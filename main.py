#!/usr/bin/env python3
import os
import re
import random
import subprocess
import sys
import time
import glob
import shutil

# ===== å®šæ•°è¨­å®š =====
SPEAKER_ID = 8                   # VOICEVOX ã®è©±è€…ID
IMAGES_DIR = "images"            # å‹•ç”»ç”¨ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
BGM_FILE = "bgm.mp3"             # èƒŒæ™¯éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«

# å…¥åŠ›å°æœ¬ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰ã‚’é…ç½®ã—ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
INPUT_DIR = "inputs"
# å‡ºåŠ›å…ˆã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = "output"
# æ¨ªå‹å‹•ç”»ã¨ç¸¦å‹å‹•ç”»ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
LANDSCAPE_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "landscape")
VERTICAL_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "vertical")

# ===== æ–°è¦è¿½åŠ ï¼šéŸ³å£°åˆæˆç”¨ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç† =====
def preprocess_for_audio(text):
    """
    éŸ³å£°åˆæˆç”¨ã«ã€ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®çµµæ–‡å­—ã‚’èª­ã¿ä¸Šã’å¯èƒ½ãªæ—¥æœ¬èªã«å¤‰æ›ã™ã‚‹
    ä¾‹: "ğŸ‘" ã‚’ "ã²ã¤ã˜" ã«å¤‰æ›ã™ã‚‹
    """
    emoji_map = {
         "ğŸ‘": "ã²ã¤ã˜",
         # å¿…è¦ã«å¿œã˜ã¦ä»–ã®çµµæ–‡å­—å¤‰æ›ã‚’è¿½åŠ 
    }
    for emoji, reading in emoji_map.items():
         text = text.replace(emoji, reading)
    return text

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° =====
def clear_directory(path):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸­èº«ã‚’å‰Šé™¤ã—ã¦å†ç”Ÿæˆã™ã‚‹"""
    if os.path.exists(path):
        shutil.rmtree(path)
    os.makedirs(path, exist_ok=True)

def run_ffmpeg(cmd):
    """FFmpeg ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°"""
    print("Running:", " ".join(cmd))
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print("ffmpeg ã‚¨ãƒ©ãƒ¼:", result.stderr.decode())
        sys.exit(1)

# ===== VOICEVOX é–¢é€£ =====
def generate_audio_chunk(text, speaker=SPEAKER_ID, chunk_index=0):
    """VOICEVOX ã® API ã‚’ä½¿ã„ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹"""
    os.makedirs("texts", exist_ok=True)
    os.makedirs("query", exist_ok=True)
    os.makedirs("wav", exist_ok=True)

    text_file = f"texts/text_chunk_{chunk_index}.txt"
    query_file = f"query/query_{chunk_index}.json"
    audio_file = f"wav/audio_{chunk_index}.wav"

    with open(text_file, "w", encoding="utf-8") as f:
        f.write(text)
    
    # audio_query ã®å®Ÿè¡Œï¼ˆcurl ã§ JSON ã‚’å–å¾—ï¼‰
    subprocess.run([
        "curl", "-s", "-X", "POST",
        f"localhost:50021/audio_query?speaker={speaker}",
        "--get", "--data-urlencode", f"text@{text_file}",
        "-o", query_file
    ], check=True)
    
    # synthesis ã®å®Ÿè¡Œï¼ˆç”Ÿæˆã—ãŸ JSON ã‚’æ¸¡ã—ã¦ wav å‡ºåŠ›ï¼‰
    subprocess.run([
        "curl", "-s",
        "-H", "Content-Type: application/json",
        "-X", "POST",
        "-d", f"@{query_file}",
        f"localhost:50021/synthesis?speaker={speaker}",
        "-o", audio_file
    ], check=True)
    
    return audio_file

def get_audio_duration(audio_file):
    """ffprobe ã‚’ä½¿ã„ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ï¼ˆç§’ï¼‰ã‚’å–å¾—ã™ã‚‹"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", audio_file],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        return float(result.stdout.strip())
    except Exception as e:
        print(f"{audio_file} ã®é•·ã•å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return 0.0

def format_srt(entries):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ SRT ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹"""
    srt_content = ""
    for i, (start, end, text) in enumerate(entries, start=1):
        start_time = time.strftime('%H:%M:%S', time.gmtime(start)) + f",{int(start % 1 * 1000):03d}"
        end_time = time.strftime('%H:%M:%S', time.gmtime(end)) + f",{int(end % 1 * 1000):03d}"
        srt_content += f"{i}\n{start_time} --> {end_time}\n{text}\n\n"
    return srt_content

def save_srt(content, filename):
    """SRT ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)

def merge_audio_files(output_file):
    """ç”Ÿæˆã•ã‚ŒãŸ wav ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã— MP3 ã«å¤‰æ›ã™ã‚‹"""
    wav_files = glob.glob("wav/audio_*.wav")
    wav_files.sort(key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))
    
    if not wav_files:
        print("çµåˆã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    list_file = "file_list.txt"
    with open(list_file, "w", encoding="utf-8") as f:
        for wav in wav_files:
            f.write(f"file '{os.path.abspath(wav)}'\n")
    
    subprocess.run([
        "ffmpeg", "-f", "concat", "-safe", "0", "-i", list_file,
        "-c", "libmp3lame", "-b:a", "192k", output_file, "-y"
    ], check=True)
    
    os.remove(list_file)
    print(f"æœ€çµ‚éŸ³å£°: {output_file}")

# ===== SRT ãƒ‘ãƒ¼ã‚¹ãƒ»å¤‰æ› =====
def srt_time_to_seconds(time_str):
    """SRT ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆä¾‹: "00:01:23,456"ï¼‰ã‚’ç§’ã«å¤‰æ›"""
    parts = re.split('[:,]', time_str)
    if len(parts) != 4:
        raise ValueError(f"ã‚¿ã‚¤ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {time_str}")
    hours, minutes, seconds, millis = parts
    return int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(millis) / 1000.0

def parse_srt(srt_path):
    """SRT ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å„å­—å¹•ãƒ–ãƒ­ãƒƒã‚¯ã®æƒ…å ±ã‚’è¿”ã™"""
    segments = []
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()
    blocks = re.split(r'\n\s*\n', content.strip())
    for block in blocks:
        lines = block.strip().splitlines()
        if len(lines) >= 3:
            times = lines[1].strip()
            m = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', times)
            if not m:
                print(f"ã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰å½¢å¼ã‚¨ãƒ©ãƒ¼: {times}")
                continue
            start_str, end_str = m.groups()
            start = srt_time_to_seconds(start_str)
            end = srt_time_to_seconds(end_str)
            text = " ".join(lines[2:]).replace('"', '\\"')
            segments.append({
                "start": start,
                "end": end,
                "duration": end - start,
                "text": text
            })
    return segments

def read_script_from_srt(srt_path):
    """
    å…¥åŠ›ã® SRT å°æœ¬ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    â€»ç•ªå·ã‚„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ç„¡è¦–ã—ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦è¿”ã™ã€‚
    """
    segments = []
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
    blocks = re.split(r'\n\s*\n', content)
    for block in blocks:
        lines = block.splitlines()
        if len(lines) >= 3:
            text = " ".join(lines[2:]).strip()
            segments.append(text)
        else:
            for line in lines:
                if line.strip() and not re.match(r'^\d+$', line.strip()):
                    segments.append(line.strip())
    return segments

def read_script(script_path):
    """
    æ±ç”¨çš„ãªå°æœ¬èª­ã¿è¾¼ã¿é–¢æ•°ã€‚
    æ‹¡å¼µå­ãŒ .srt ã®å ´åˆã¯ SRT ã¨ã—ã¦ã€.txt ã®å ´åˆã¯å„è¡Œã‚’ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚
    """
    if script_path.lower().endswith(".srt"):
        return read_script_from_srt(script_path)
    elif script_path.lower().endswith(".txt"):
        with open(script_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    else:
        print(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {script_path}")
        return []

# ===== å‹•ç”»ç”Ÿæˆ =====
def process_video(srt_file, audio_file, output_video, vertical=False, image_files=None):
    """
    SRT ã¨éŸ³å£°ã€ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆã—ã€å­—å¹•ã‚’ç„¼ãä»˜ã‘ã‚‹å‡¦ç†  
    vertical: ç¸¦å‹å‹•ç”»ã®å ´åˆã¯ True, æ¨ªå‹ã®å ´åˆã¯ False
    image_files: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã€‚Noneã®å ´åˆã¯è‡ªå‹•ã§å–å¾—ã™ã‚‹ã€‚
    """
    print("SRT ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ä¸­...")
    segments = parse_srt(srt_file)
    if not segments:
        print("æœ‰åŠ¹ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒ SRT ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)
    
    # ç¸¦å‹/æ¨ªå‹ãã‚Œãã‚Œã®ã‚¹ã‚±ãƒ¼ãƒ«ãƒ»å­—å¹•è¨­å®š
    # â€» çµµæ–‡å­—è¡¨ç¤ºã®ãŸã‚ã€Apple Color Emoji ã‚’ä½¿ç”¨
    if vertical:
        scale_filter = "scale=-1:1920,crop=1080:1920,format=yuv420p"
        # éã‚«ãƒ©ãƒ¼çµµæ–‡å­—ç”¨ã«ã€Symbolaï¼ˆã¾ãŸã¯ä»–ã®éã‚«ãƒ©ãƒ¼çµµæ–‡å­—ãƒ•ã‚©ãƒ³ãƒˆï¼‰ã‚’æŒ‡å®šã™ã‚‹
        subtitle_style = "FontName=Noto Sans CJK JP\\,Symbola,FontSize=24,MarginV=50"
    else:
        scale_filter = "scale=1920:1080,format=yuv420p"
        subtitle_style = subtitle_style = "FontName=Noto Sans CJK JP\\,Symbola,FontSize=30"
    
    # ç”»åƒä¸€è¦§ã®å–å¾—ï¼ˆå¤–éƒ¨ã‹ã‚‰æ¸¡ã•ã‚Œãªã‘ã‚Œã°è‡ªå‹•å–å¾—ï¼‰
    if image_files is None:
        valid_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')
        if not os.path.isdir(IMAGES_DIR):
            print(f"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{IMAGES_DIR}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            sys.exit(1)
        image_files = [os.path.join(IMAGES_DIR, f) for f in os.listdir(IMAGES_DIR) if f.lower().endswith(valid_ext)]
        if not image_files:
            print("ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«æœ‰åŠ¹ãªç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            sys.exit(1)
        random.shuffle(image_files)
    
    if len(segments) > len(image_files):
        print("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ã‚ˆã‚Šç”»åƒæ•°ãŒå°‘ãªã„ãŸã‚å‡¦ç†ã§ãã¾ã›ã‚“ã€‚")
        sys.exit(1)
    
    # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«å‹•ç”»ï¼ˆç”»åƒã®é™æ­¢ç”»ï¼‹æŒ‡å®šæ™‚é–“ï¼‰ã‚’ç”Ÿæˆ
    segment_files = []
    for i, seg in enumerate(segments):
        duration = seg["duration"]
        image_path = image_files[i]
        segment_filename = f"segment_{i:03d}.mp4"
        segment_files.append(segment_filename)
        cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-i", image_path,
            "-t", f"{duration:.3f}",
            "-vf", scale_filter,
            "-r", "30",
            "-c:v", "libx264",
            segment_filename
        ]
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {i+1}/{len(segments)}: image={image_path}, duration={duration:.3f}s")
        run_ffmpeg(cmd)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé€£çµç”¨ãƒªã‚¹ãƒˆä½œæˆ
    concat_list = "segments.txt"
    with open(concat_list, "w", encoding="utf-8") as f:
        for seg_file in segment_files:
            f.write(f"file '{os.path.abspath(seg_file)}'\n")
    
    concat_video = "temp_video.mp4"
    cmd = [
        "ffmpeg", "-y",
        "-f", "concat",
        "-safe", "0",
        "-i", concat_list,
        "-c", "copy",
        concat_video
    ]
    run_ffmpeg(cmd)
    
    # BGM ã‚’åŠ ãˆãŸéŸ³å£°åˆæˆ
    video_audio = "video_with_audio.mp4"
    cmd = [
        "ffmpeg", "-y",
        "-i", concat_video,
        "-i", audio_file,
        "-stream_loop", "-1", "-i", BGM_FILE,
        "-filter_complex", "[1:a]volume=1[a1];[2:a]volume=0.3[a2];[a1][a2]amix=inputs=2:duration=shortest[out]",
        "-map", "0:v",
        "-map", "[out]",
        "-c:v", "copy",
        "-c:a", "aac",
        "-shortest",
        video_audio
    ]
    run_ffmpeg(cmd)
    
    # å­—å¹•ã‚’å‹•ç”»ã«ç„¼ãä»˜ã‘ï¼ˆUTF-8 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ force_style ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼‰
    cmd = [
        "ffmpeg", "-y",
        "-i", video_audio,
        "-vf", f"subtitles={srt_file}:charenc=UTF-8:force_style='{subtitle_style}'",
        "-c:a", "copy",
        output_video
    ]
    run_ffmpeg(cmd)
    print("æœ€çµ‚å‡ºåŠ›å‹•ç”»:", output_video)
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
    temp_files = segment_files + [concat_list, concat_video, video_audio]
    for f in temp_files:
        if os.path.exists(f):
            os.remove(f)
    print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

# ===== å°æœ¬ï¼‘ä»¶æ¯ã®å‡¦ç† =====
def process_script(script_path):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå°æœ¬ï¼ˆscript_pathï¼‰ã‹ã‚‰
    éŸ³å£°ç”Ÿæˆãƒ»SRT å†ä½œæˆãƒ»å‹•ç”»ä½œæˆã‚’å®Ÿè¡Œã—ã€
    æ¨ªå‹å‹•ç”»ã¨ç¸¦å‹å‹•ç”»ã‚’ãã‚Œãã‚Œåˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    print("=" * 40)
    print(f"å°æœ¬ãƒ•ã‚¡ã‚¤ãƒ«: {script_path} ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªã‚¢
    for folder in ["texts", "query", "wav"]:
        clear_directory(folder)
    
    # å°æœ¬ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆæ‹¡å¼µå­ã«å¿œã˜ã¦ï¼‰
    lines = read_script(script_path)
    if not lines:
        print(f"{script_path} ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    srt_entries = []
    current_time = 0.0
    # å„ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰éŸ³å£°ç”Ÿæˆã¨ãã®é•·ã•ã®è¨ˆæ¸¬
    for i, line in enumerate(lines):
        print(f"ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(lines)} å‡¦ç†ä¸­: {line}")
        # éŸ³å£°åˆæˆå‰ã«çµµæ–‡å­—ã‚’å¤‰æ›ï¼ˆä¾‹: ğŸ‘ -> ã²ã¤ã˜ï¼‰
        processed_text = preprocess_for_audio(line)
        audio_file = generate_audio_chunk(processed_text, SPEAKER_ID, i)
        duration = get_audio_duration(audio_file)
        start_time = current_time
        end_time = start_time + duration
        current_time = end_time
        # å­—å¹•ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—ã‚‚ãã®ã¾ã¾è¡¨ç¤ºï¼‰
        srt_entries.append((start_time, end_time, line))
    
    # ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‹ã‚‰æ–°ãŸãª SRT ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    generated_srt = "generated.srt"
    srt_content = format_srt(srt_entries)
    save_srt(srt_content, generated_srt)
    
    # å…¨ãƒãƒ£ãƒ³ã‚¯ã®éŸ³å£°ã‚’çµåˆã—ã¦ï¼‘ã¤ã® MP3 ã«
    final_audio = "final_audio.mp3"
    merge_audio_files(final_audio)
    
    # å…±é€šã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦ã€ä¸¡æ–¹ã®å‹•ç”»ã§åŒã˜é †ç•ªã‚’ä½¿ç”¨
    valid_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')
    if not os.path.isdir(IMAGES_DIR):
        print(f"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{IMAGES_DIR}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    common_image_files = [os.path.join(IMAGES_DIR, f) for f in os.listdir(IMAGES_DIR) if f.lower().endswith(valid_ext)]
    if not common_image_files:
        print("ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«æœ‰åŠ¹ãªç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)
    random.shuffle(common_image_files)
    
    # æ¨ªå‹å‹•ç”»ã®ç”Ÿæˆ
    landscape_output_temp = "final_output_landscape.mp4"
    process_video(generated_srt, final_audio, landscape_output_temp, vertical=False, image_files=common_image_files)
    
    # ç¸¦å‹å‹•ç”»ï¼ˆverticalå‹•ç”»ï¼‰ã®ç”Ÿæˆ
    vertical_output_temp = "final_output_vertical.mp4"
    process_video(generated_srt, final_audio, vertical_output_temp, vertical=True, image_files=common_image_files)
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­é™¤ãï¼‰ã‚’åˆ©ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
    input_name = os.path.splitext(os.path.basename(script_path))[0]
    landscape_dest = os.path.join(LANDSCAPE_OUTPUT_DIR, f"{timestamp}_{input_name}_landscape.mp4")
    vertical_dest = os.path.join(VERTICAL_OUTPUT_DIR, f"{timestamp}_{input_name}_vertical.mp4")
    shutil.move(landscape_output_temp, landscape_dest)
    shutil.move(vertical_output_temp, vertical_dest)
    print(f"æ¨ªå‹å‹•ç”»ã‚’ {landscape_dest} ã«ã€ç¸¦å‹å‹•ç”»ã‚’ {vertical_dest} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚\n")

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    # ãƒ™ãƒ¼ã‚¹å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨æ¨ªå‹ãƒ»ç¸¦å‹ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(LANDSCAPE_OUTPUT_DIR, exist_ok=True)
    os.makedirs(VERTICAL_OUTPUT_DIR, exist_ok=True)
    print(f"å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
    
    # inputs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® .txt ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    script_files = glob.glob(os.path.join(INPUT_DIR, "*.txt"))
    if not script_files:
        print(f"{INPUT_DIR} å†…ã« .txt ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)
    
    for script in script_files:
        process_script(script)
    
    print("ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
